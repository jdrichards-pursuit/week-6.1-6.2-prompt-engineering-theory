{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 6.1: Prompt Engineering\n",
    "\n",
    "**Note:** In this lesson you will be given examples for creating prompts based on using data and pandas as well as non-data examples. You will be shown how to structure your prompts for both types of examples.\n",
    "\n",
    "## <ins>Setup</ins>  \n",
    "\n",
    "**Reminder:** Don't forget to setup your virtual environment, choose your python interpreter and install the ipykernel.\n",
    "\n",
    "### 1. Retrieving Your API Key\n",
    "\n",
    "Before we begin, you will need to retrieve your API key from Gemini.\n",
    "\n",
    "Use the following set of instructions to sign up for an account and retrieve your API key.\n",
    "\n",
    "[Gemini API Key](https://github.com/jdrichards-pursuit/gemini-api-key-acquire?tab=readme-ov-file)\n",
    "\n",
    "### 2. Setting Up Your Environment Variables\n",
    "\n",
    "Now that you have your API key, you can set up your environment variables.\n",
    "\n",
    "Create a new file called `.env` and add the following line of code:\n",
    "\n",
    "```bash\n",
    "API_KEY=<your-api-key>\n",
    "```\n",
    "\n",
    "### 3. Installing Required Libraries\n",
    "\n",
    "Now that you have your API key, you can install the required libraries.\n",
    "\n",
    "```bash\n",
    "pip install python-dotenv\n",
    "```\n",
    "\n",
    "### 4. Importing Required Libraries\n",
    "\n",
    "Now that you have your API key, you can import the required libraries. When you run this code, it will print your API key to the console.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "\n",
    "print(api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After viewing your API key, you may now want to remove the print statement for security reasons.\n",
    "\n",
    "### 5. Importing Required Libraries\n",
    "\n",
    "For this lesson you will also need to install the following libraries:\n",
    "\n",
    "```bash\n",
    "pip install google-generativeai pandas\n",
    "```\n",
    "\n",
    "### 6. Import Packages\n",
    "\n",
    "Next, import these packages into your environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Set Up API Key\n",
    "\n",
    "You will need to set up your API key using your already created environment variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['API_KEY'] = api_key\n",
    "genai.configure(api_key=os.environ['API_KEY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <ins>Prompt Process Under the Hood</ins>\n",
    "\n",
    "Before we begin digging into prompt engineering, let's familiarize ourselves on a high level with what happens under the hood when we send a prompt. This is definitely 'above our paygrade' and not what we will be focusing on, but it is good to be aware of. Take a look at this link which describes [The Process of A Prompt](https://github.com/jdrichards-pursuit/prompt-process-explained).\n",
    "\n",
    "### Parts of a Prompt\n",
    "\n",
    "When creating a prompt using the Gemini API, there are three main parts to consider:\n",
    "\n",
    "1. **Model**: The model you are using to generate the response. In our case, we are using the `gemini-1.5-flash` model.\n",
    "2. **Parameters**: Parameters are additional settings or options that you can send to the model to guide the response. We will cover these in more detail later in the lesson.\n",
    "3. **Prompt**: A prompt is the input or instruction given to an AI model to elicit a specific response or output. It's the text that guides the AI in understanding what kind of information or task you're requesting.\n",
    "\n",
    "\n",
    "### Model\n",
    "For this lesson, we will be using the `gemini-1.5-flash` model because it is free and '...is a fast and versatile multimodal model for scaling across diverse tasks.' to quote the [Gemini API Documentation](https://ai.google.dev/gemini-api/docs/models/gemini#gemini-1.5-flash).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "When we send a prompt to the model, we can also send parameters to the model. These parameters are used to guide the model's response. In Gemini API, there are several parameters we can send to the model, but for now we will focus on the following:\n",
    "\n",
    "- `temperature`: This parameter controls the randomness of the model's response. A temperature of 0 is deterministic, meaning the model will always return the same response for a given prompt. A temperature between 0 and 1 will make the response more random.\n",
    "- `max_output_tokens`: This parameter controls the maximum number of tokens in the model's response.\n",
    "- `num_return_sequences`: This parameter controls the number of alternative completions to generate.\n",
    "- `min_length`: This parameter controls the minimum number of tokens in the model's response.\n",
    "- `max_length`: This parameter controls the maximum number of tokens in the model's response.\n",
    "\n",
    "\n",
    "There is also a are many more parameters, but we will not focus on those for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Temperature\n",
    "\n",
    "- This parameter controls the randomness of the generated text.\n",
    "\n",
    "- Think of it like adjusting the \"creativity\" or \"originality\" of the generated text.\n",
    "\n",
    "- A higher temperature (e.g., 0.9) means the API will generate more unique and creative text, but it might also be less coherent or grammatically correct.\n",
    "\n",
    "- A lower temperature (e.g., 0.1) means the API will generate more predictable and coherent text, but it might also be less creative or original.\n",
    "By default, the API uses a temperature of 0.5, which is a good balance between creativity and coherence.\n",
    "\n",
    "- By default, the API uses a temperature of 0.5, which is a good balance between creativity and coherence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Max Output Tokens\n",
    "\n",
    "- This parameter sets the maximum number of tokens in the generated text.\n",
    "- A token is the smallest unit of text that the model can generate.\n",
    "- If you set max_output_tokens to 20, the API will generate text that's around 20 tokens long."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Num Return Sequences\n",
    "\n",
    "- This parameter sets the number of alternative completions to generate.\n",
    "- If you set num_return_sequences to 3, the API will generate 3 different completions for the same prompt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Min Length\n",
    "\n",
    "- This parameter sets the minimum number of characters (letters, spaces, punctuation) in the generated text.\n",
    "- Think of it like setting a word count for a minimum number of sentences. You might ask someone to write at least 5 sentences.\n",
    "- The API will generate text that's as close to the minimum length as possible, but it might not reach the exact limit.\n",
    "- If you set min_length to 20, the API will generate text that's around 20 characters long.\n",
    "- There is no default value for this parameter, so you will always need to set it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Max Length\n",
    "\n",
    "- This parameter sets the maximum number of characters (letters, spaces, punctuation) in the generated text.\n",
    "- Think of it like setting a word count for a maximum number of sentences. You might ask someone to write at most 5 sentences.\n",
    "- The API will generate text that's as close to the maximum length as possible, but it might not reach the exact limit.\n",
    "- If you set max_length to 20, the API will generate text that's around 20 characters long.\n",
    "- There is no default value for this parameter, so you will always need to set it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Parameters\n",
    "\n",
    "You do not have to set all of these parameters and we will not explain them all,, but it is good to be aware of them. When they are not specified, the API will use the default values. The defaults are:\n",
    "\n",
    "```python\n",
    "generation_config = {\n",
    "    \"model\": \"gemini-1.5-flash\",\n",
    "    \"temperature\": 0.7,\n",
    "    \"max_output_tokens\": 2048,\n",
    "    \"num_return_sequences\": 1,\n",
    "    \"top_p\": 1,\n",
    "    \"top_k\": 32,\n",
    "    \"stop_sequences\": [],\n",
    "    \"candidate_count\": 1,\n",
    "    \"safety_settings\": [\n",
    "        {\n",
    "            \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
    "            \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "        },\n",
    "        {\n",
    "            \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
    "            \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "        },\n",
    "        {\n",
    "            \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "            \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "        },\n",
    "        {\n",
    "            \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "            \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "        }\n",
    "    ],\n",
    "    \"prompt_feedback\": {\n",
    "        \"safety_ratings\": []\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets create a function, `get_completion`, that will submit a prompt to the Gemini API and return the response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gemini-1.5-flash\", **kwargs):\n",
    "    model = genai.GenerativeModel(model)\n",
    "    \n",
    "    # Create a generation_config dictionary with default values\n",
    "    generation_config = {\n",
    "        \"temperature\": 0.8,\n",
    "        \"min_length\": 20,\n",
    "        \"max_length\": 200,\n",
    "    }\n",
    "    \n",
    "    # Update generation_config with any provided kwargs\n",
    "    generation_config.update(kwargs)\n",
    "    \n",
    "    response = model.generate_content(prompt, generation_config=generation_config)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Walkthrough of the Code\n",
    "\n",
    "1. We first create a function called `get_completion` that takes in a prompt and any number of keyword arguments called `kwargs`.\n",
    "    - `**kwargs` allows us to pass in any number of keyword arguments to the function.\n",
    "    - the double asterisk is used to unpack the keyword arguments into a dictionary. In JavaScript, this would be `{...args}`.\n",
    "\n",
    "2. We then create a `generation_config` dictionary with default values for the parameters we want to default to.\n",
    "\n",
    "3. We then update the `generation_config` dictionary with any provided keyword arguments. This allows us to override the default values when we call the function.\n",
    "\n",
    "4. We then generate the response from the model using the `generate_content` method on the model dictionary.\n",
    "\n",
    "5. Finally, we return the response.\n",
    "\n",
    "### Let's call the function with our prompt and print the response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_completion(\n",
    "    prompt,\n",
    "    temperature=0.9,\n",
    "    max_output_tokens=1000\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <ins>Prompt Engineering Techniques</ins>\n",
    "\n",
    "Prompt engineering is a crucial skill for effectively leveraging AI language models like ChatGPT. It involves crafting inputs that guide the AI to produce desired outputs. Mastering these techniques allows users to get more accurate, relevant, and useful responses from AI systems.\n",
    "\n",
    "Key prompt engineering techniques include:\n",
    "- Formulating clear and specific questions\n",
    "- Providing relevant context\n",
    "- Specifying desired output format\n",
    "- Including examples to anchor prompts\n",
    "- Breaking down complex tasks into steps\n",
    "- Encouraging multiple alternatives\n",
    "- Iterative prompting and refinement\n",
    "\n",
    "These techniques help improve the AI's reasoning capabilities, enable more structured outputs, and enhance overall interaction quality with language models.\n",
    "\n",
    "### 1. Formulating Effective Questions\n",
    "\n",
    "Whether you're analyzing data or seeking general information, asking clear and specific questions is crucial. Let's explore how to frame your queries effectively in both data-related and general contexts.\n",
    "\n",
    "#### Clear vs. Vague Instructions\n",
    "\n",
    "#### Data Example:\n",
    "```python\n",
    "# Good: Clear and specific question\n",
    "\"\"\"\n",
    "What is the average sale price of houses with more than 3 bedrooms \n",
    "in the 'Seattle' area from our housing dataset?\n",
    "\"\"\"\n",
    "\n",
    "# Bad: Vague and ambiguous question\n",
    "\"\"\"\n",
    "What can you tell me about the houses in the dataset?\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "#### Non-Data Example:\n",
    "```python\n",
    "# Good: Clear and specific question\n",
    "\"\"\"\n",
    "What are the three main causes of deforestation in the Amazon rainforest \n",
    "over the past decade?\n",
    "\"\"\"\n",
    "\n",
    "# Bad: Vague and ambiguous question\n",
    "\"\"\"\n",
    "Tell me about forests.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "### Practice\n",
    "Imagine you're asking someone to explain the concept of climate change.\n",
    "\n",
    "1. Write a vague instruction for explaining climate change.\n",
    "2. Then, rewrite the instruction to make it clear and specific.\n",
    "3. Show the class what you wrote for both prompts and explain the differences in the two model responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment and uncomment your prompts one at a time to see the difference\n",
    "# Your vague instruction:\n",
    "prompt = \"\"\"\n",
    "\"\"\"\n",
    "# Your clear and specific instruction:\n",
    "\n",
    "prompt = \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(\n",
    "    prompt\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Providing Relevant Context\n",
    "\n",
    "##### Data Example:\n",
    "```python\n",
    "# Good: Includes relevant context\n",
    "\"\"\"\n",
    "Our dataset 'sales.csv' contains columns for 'price', 'bedrooms', and 'location'.\n",
    "Can you show me how to calculate the median price for each bedroom category?\n",
    "\"\"\"\n",
    "\n",
    "# Bad: Lacks necessary context\n",
    "\"\"\"\n",
    "Calculate the median prices.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "##### Non-Data Example:\n",
    "```python\n",
    "# Good: Includes relevant context\n",
    "\"\"\"\n",
    "In the context of object-oriented programming in Python, \n",
    "can you explain the concept of inheritance with a simple example?\n",
    "\"\"\"\n",
    "\n",
    "# Bad: Lacks necessary context\n",
    "\"\"\"\n",
    "What is inheritance?\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "### Practice\n",
    "Imagine you're asking for advice on how to care for a specific type of houseplant.\n",
    "\n",
    "1. Write a prompt without providing any context.\n",
    "2. Then, rewrite the prompt to include relevant context.\n",
    "3. Show the class what you wrote for both prompts and explain the differences in the two model responses.\n",
    "\n",
    "Relevant context for houseplant care could include:\n",
    "- Plant species or variety\n",
    "- Plant size and age\n",
    "- Light conditions\n",
    "- Location in the home\n",
    "- Temperature and humidity levels\n",
    "- Current plant health\n",
    "- Watering habits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment and uncomment your prompts one at a time to see the difference\n",
    "# Your prompt without context:\n",
    "prompt = \"\"\"\n",
    "\"\"\"\n",
    "# Your prompt with context:\n",
    "prompt = \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(\n",
    "    prompt\n",
    ")\n",
    "\n",
    "print(response) # this is the response from the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3. Specifying Constraints in Your Queries\n",
    "\n",
    "When working with data or seeking information, it's important to specify any constraints or limitations in your request. This helps ensure you get precisely the information you need in the format you want.\n",
    "\n",
    "#### Data Example:\n",
    "\n",
    "##### Good: Specifies constraints clearly\n",
    "\n",
    "```python\n",
    "\"\"\"\n",
    "From our 'employee_data.csv', analyze the salary distribution for employees \n",
    "who joined in the last 2 years. Provide the 25th, 50th, and 75th percentiles, \n",
    "and limit your response to a maximum of 4 bullet points.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "##### Bad: Lacks specific constraints\n",
    "\n",
    "```python\n",
    "\"\"\"\n",
    "Analyze the salary distribution from the employee data.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "#### Non-Data Example:\n",
    "\n",
    "##### Good: Specifies constraints clearly\n",
    "\n",
    "```python\n",
    "\"\"\"\n",
    "Explain the concept of recursion in programming. Use exactly 3 sentences \n",
    "and provide a simple example that doesn't involve calculating factorials \n",
    "or Fibonacci numbers.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "##### Bad: Lacks specific constraints\n",
    "\n",
    "```python\n",
    "\"\"\"\n",
    "Explain recursion in programming.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "Remember: By specifying constraints such as time periods, specific metrics, response format, or content limitations, you can ensure that the response meets your needs exactly. This is crucial whether you're analyzing data from a CSV file or seeking general information on a topic.\n",
    "\n",
    "### Practice\n",
    "\n",
    "Imagine you're asking for recommendations for a book to read.\n",
    "\n",
    "1. Write a prompt without specifying any constraints.\n",
    "2. Then, rewrite the prompt to include specific constraints. \n",
    "3. Show the class what you wrote for both prompts and explain the differences in the two model responses.\n",
    "\n",
    "Consider including constraints such as:\n",
    "\n",
    "- Genre (e.g., science fiction, mystery, historical fiction)\n",
    "- Publication date (e.g., published in the last 5 years)\n",
    "- Awards or recognition (e.g., has won at least one major literary award)\n",
    "- Themes or topics (e.g., features themes of artificial intelligence or space exploration)\n",
    "- Target audience (e.g., suitable for young adult readers)\n",
    "- Length (e.g., under 400 pages long)\n",
    "- Format of the recommendation (e.g., provide title, author, and a brief description)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Specifying Output Format\n",
    "\n",
    "When working with data or seeking information, you can guide the model to provide responses in a specific format. This is particularly useful when you need structured outputs for further processing or analysis. This structured output can be in the form of a JSON, a table, a list, etc. Your example for this structure can either be a partial example or a full example.\n",
    "\n",
    "##### Data Example:\n",
    "\n",
    "#### Prompt without format specification:\n",
    "\n",
    "```python\n",
    "\"\"\"\n",
    "Analyze the top 3 selling products from our 'annual_sales.csv' file.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "#### Possible Response:\n",
    "\n",
    "```\n",
    "Based on the analysis of the 'annual_sales.csv' file, the top 3 selling products are:\n",
    "\n",
    "1. Smartphone X: This product led in units sold with 50,000 units, generating a revenue of $25,000,000.\n",
    "\n",
    "2. Laptop Pro: While selling fewer units (30,000) than the Smartphone X, it generated the highest revenue at $45,000,000 due to its higher price point.\n",
    "\n",
    "3. Wireless Earbuds: This product showed strong unit sales at 100,000, but had a lower revenue of $15,000,000, indicating a lower price point.\n",
    "\n",
    "These top products demonstrate a mix of high-volume and high-value items, with smartphones leading in units sold and laptops in revenue generation.\n",
    "```\n",
    "\n",
    "To ensure a specific JSON format, you can provide the beginning of the JSON structure:\n",
    "\n",
    "#### Prompt with format specification (using partial JSON structure):\n",
    "\n",
    "```python\n",
    "prompt = \"\"\"\n",
    "Analyze the top 3 selling products from our 'annual_sales.csv' file. \n",
    "Provide the output in the following JSON format:\n",
    "\n",
    "{\n",
    "  \"top_products\": [\n",
    "    {\n",
    "      \"rank\": 1,\n",
    "      \"name\": \n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "#### Possible Response:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"top_products\": [\n",
    "    {\n",
    "      \"rank\": 1,\n",
    "      \"name\": \"Smartphone X\",\n",
    "      \"units_sold\": 50000,\n",
    "      \"revenue\": 25000000\n",
    "    },\n",
    "    {\n",
    "      \"rank\": 2,\n",
    "      \"name\": \"Laptop Pro\",\n",
    "      \"units_sold\": 30000,\n",
    "      \"revenue\": 45000000\n",
    "    },\n",
    "    {\n",
    "      \"rank\": 3,\n",
    "      \"name\": \"Wireless Earbuds\",\n",
    "      \"units_sold\": 100000,\n",
    "      \"revenue\": 15000000\n",
    "    }\n",
    "  ],\n",
    "  \"analysis\": \"The top 3 products demonstrate a balance between high-volume and high-value items. Smartphone X leads in units sold, while Laptop Pro generates the highest revenue. Wireless Earbuds show strong unit sales but lower per-unit revenue.\"\n",
    "}\n",
    "```\n",
    "\n",
    "## Non-Data Example:\n",
    "\n",
    "#### Prompt without format specification:\n",
    "\n",
    "```python\n",
    "prompt = \"\"\"\n",
    "Describe the key features of Python programming language.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "#### Possible Response:\n",
    "\n",
    "```\n",
    "Python is a popular programming language known for several key features:\n",
    "\n",
    "1. Easy to learn and read syntax: Python uses indentation and simple keywords, making it accessible for beginners and easy to read for all developers.\n",
    "\n",
    "2. Interpreted language: Python code is executed line by line, allowing for rapid development and debugging.\n",
    "\n",
    "3. Dynamically typed: Variables in Python can change types, providing flexibility in programming.\n",
    "\n",
    "4. Object-oriented programming support: Python supports OOP concepts like classes, inheritance, and encapsulation.\n",
    "\n",
    "5. Extensive standard library: Python comes with a large library of pre-built modules, reducing the need for external dependencies.\n",
    "\n",
    "6. Cross-platform compatibility: Python programs can run on various operating systems with minimal modifications.\n",
    "\n",
    "Python is widely used in web development, data analysis, artificial intelligence, machine learning, scientific computing, and automation tasks. The latest stable version as of May 2021 is 3.9.5.\n",
    "```\n",
    "\n",
    "To ensure a specific JSON format, you can provide the beginning of the JSON structure:\n",
    "\n",
    "#### Prompt with format specification (using partial JSON structure):\n",
    "\n",
    "```python\n",
    "prompt = \"\"\"\n",
    "Describe the key features of Python programming language. \n",
    "Provide the output in the following JSON format:\n",
    "\n",
    "{\n",
    "  \"language\": \"Python\",\n",
    "  \"features\": [\n",
    "    {\n",
    "      \"name\": \n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "#### Possible Response:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"language\": \"Python\",\n",
    "  \"features\": [\n",
    "    {\n",
    "      \"name\": \"Easy to learn and read syntax\",\n",
    "      \"description\": \"Python uses indentation and simple keywords, making it accessible for beginners and easy to read for all developers.\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Interpreted language\",\n",
    "      \"description\": \"Python code is executed line by line, allowing for rapid development and debugging.\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Dynamically typed\",\n",
    "      \"description\": \"Variables in Python can change types, providing flexibility in programming.\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Extensive standard library\",\n",
    "      \"description\": \"Python comes with a large library of pre-built modules, reducing the need for external dependencies.\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Cross-platform compatibility\",\n",
    "      \"description\": \"Python programs can run on various operating systems with minimal modifications.\"\n",
    "    }\n",
    "  ],\n",
    "  \"version\": \"3.9.5\",\n",
    "  \"popular_applications\": [\"Web development\", \"Data analysis\", \"AI and machine learning\", \"Scientific computing\"]\n",
    "}\n",
    "```\n",
    "\n",
    "Remember: By providing a structure for the desired output format, you can guide the model to generate responses in a consistent and easily parseable format, whether you're analyzing data from a CSV file or seeking information on programming concepts.\n",
    "\n",
    "### Practice\n",
    "\n",
    "Imagine you're asking for information about a historical event.\n",
    "\n",
    "1. Write a prompt without specifying any output format.\n",
    "2. Rewrite the prompt to include a specific output format.\n",
    "3. Show the class what you wrote for both prompts and explain the differences in the two model responses.\n",
    "\n",
    "**Historical events could include:**\n",
    "\n",
    "- World War II\n",
    "- The Great Fire of London\n",
    "- The French Revolution\n",
    "- The American Revolution  \n",
    "\n",
    "**Consider formats such as:**\n",
    "\n",
    "- Bulleted list\n",
    "- Timeline\n",
    "- Table\n",
    "- Pros and cons list\n",
    "- Q&A format\n",
    "- Step-by-step guide\n",
    "- Comparison chart\n",
    "- Brief paragraph summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment and uncomment your prompts one at a time to see the difference\n",
    "# Your prompt without specifying output format:\n",
    "prompt = \"\"\"\n",
    "\"\"\"\n",
    "# Your prompt with specifying output format:\n",
    "prompt = \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(\n",
    "    prompt\n",
    ")\n",
    "\n",
    "print(response) # this is the response from the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Including Few-Shot Examples in Your Queries\n",
    "\n",
    "When working with data or seeking information, providing examples in your prompt can help guide the model to produce more accurate and appropriately formatted responses. This technique is called \"few-shot learning\" and can be applied to both data analysis tasks and general inquiries.\n",
    "\n",
    "#### Definitions:\n",
    "\n",
    "- **Zero-shot prompt**: A prompt that provides no examples, relying solely on instructions.\n",
    "- **One-shot prompt**: A prompt that includes a single example to guide the model's response.\n",
    "- **Few-shot prompt**: A prompt that contains multiple examples to demonstrate the desired pattern or format.\n",
    "\n",
    "#### Data Example:\n",
    "\n",
    "##### Zero-shot prompt:\n",
    "\n",
    "```python\n",
    "prompt = \"\"\"\n",
    "Analyze the sales data from our 'quarterly_sales.csv' file and provide a summary \n",
    "of the top-performing products.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "##### Few-shot prompt:\n",
    "\n",
    "```python\n",
    "prompt = \"\"\"\n",
    "Here are two examples of how to analyze and summarize sales data:\n",
    "\n",
    "Example 1:\n",
    "Input: Analyze Q1 sales for electronic products\n",
    "Output:\n",
    "1. Top product: Smartphones (Revenue: $1.2M, Units sold: 5000)\n",
    "2. Fastest growing: Wireless earbuds (300% growth from last quarter)\n",
    "3. Underperformer: Tablets (20% decline in sales)\n",
    "\n",
    "Example 2:\n",
    "Input: Summarize Q2 sales for home appliances\n",
    "Output:\n",
    "1. Best seller: Robot vacuums (Revenue: $800K, Units sold: 2000)\n",
    "2. Surprise hit: Smart thermostats (150% increase in demand)\n",
    "3. Needs attention: Microwave ovens (10% drop in market share)\n",
    "\n",
    "Now, using the same format, analyze the sales data from our 'quarterly_sales.csv' \n",
    "file and provide a summary of the top-performing products for Q3.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "#### Non-Data Example:\n",
    "\n",
    "##### One-shot prompt:\n",
    "\n",
    "```python\n",
    "prompt = \"\"\"\n",
    "Here's an example of how to explain a programming concept concisely:\n",
    "\n",
    "Concept: List comprehension in Python\n",
    "Explanation: A compact way to create lists based on existing lists or iterables, \n",
    "combining a for loop and a conditional statement in a single line of code.\n",
    "\n",
    "Now, using the same concise format, explain the concept of 'decorator' in Python.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "##### Few-shot prompt:\n",
    "\n",
    "```python\n",
    "prompt = \"\"\"\n",
    "Here are two examples of explaining programming concepts:\n",
    "\n",
    "Concept: List comprehension in Python\n",
    "Explanation: A compact way to create lists based on existing lists or iterables, \n",
    "combining a for loop and a conditional statement in a single line of code.\n",
    "\n",
    "Concept: Lambda functions in Python\n",
    "Explanation: Anonymous, inline functions defined using the 'lambda' keyword, \n",
    "typically used for simple operations and as arguments to higher-order functions.\n",
    "\n",
    "Now, using the same concise format, explain the following two concepts:\n",
    "1. Decorator in Python\n",
    "2. Generator expression in Python\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "Remember: Including examples in your prompts can significantly improve the relevance and format of the responses, whether you're analyzing data from a CSV file or seeking explanations for programming concepts.\n",
    "\n",
    "### Practice\n",
    "\n",
    "Your goal is to create prompts that will instruct a language model to convert informal text messages into more formal, professional language.\n",
    "\n",
    "1.  Write a zero-shot prompt for this task without providing any examples.\n",
    "2. Then, write a few-shot prompt that includes at least two examples to guide the model's response.\n",
    "3. Show the class what you wrote for both prompts and explain the differences in the two model responses.\n",
    "\n",
    "Suggested example type:\n",
    "\n",
    "Informal: \"Hey! Can u send me that report ASAP? Thx!\"\n",
    "Formal: \"Hello, Could you please send me that report as soon as possible? Thank you.\"\n",
    "\n",
    "Use your own examples to practice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment and uncomment your prompts one at a time to see the difference\n",
    "# Your zero-shot prompt:\n",
    "prompt = \"\"\"\n",
    "\"\"\"\n",
    "# Your few-shot prompt:\n",
    "prompt = \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(\n",
    "    prompt\n",
    ")\n",
    "\n",
    "print(response) # this is the response from the model   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. System Instructions: Shaping AI Behavior\n",
    "\n",
    "System instructions, also known as system prompts, are powerful tools for defining how an AI model should behave and respond. These instructions can be used to create specialized assistants, set response formats, and limit the scope of the AI's knowledge or capabilities.\n",
    "\n",
    "By using system instructions, you can essentially create a custom `AI Assistant` tailored to specific tasks or domains. For example, you could create:\n",
    "\n",
    "- A data analysis assistant\n",
    "- A language tutor\n",
    "- A creative writing coach\n",
    "- A technical support specialist\n",
    "\n",
    "The system instruction sets the \"personality\" and capabilities of the assistant.\n",
    "\n",
    "Certainly! I'll provide both a good and a bad example of using system instructions to create a specialized assistant. This contrast will help illustrate the importance of well-crafted system instructions.\n",
    "\n",
    "#### Bad Example: Vague General Assistant\n",
    "\n",
    "##### System Instruction (Bad):\n",
    "\n",
    "```python\n",
    "system_instruction = \"\"\"\n",
    "You are a helpful assistant. Answer user questions.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "##### User Prompt:\n",
    "\n",
    "```python\n",
    "user_prompt = \"\"\"\n",
    "I'm a 30-year-old woman, 165 cm tall, weighing 70 kg. I exercise 3 times a week. \n",
    "Can you suggest a balanced meal plan for weight loss?\n",
    "\"\"\"\n",
    "\n",
    "full_prompt = f\"{system_instruction}\\n\\n{user_prompt}\"\n",
    "response = get_completion(full_prompt)\n",
    "print(response)\n",
    "```\n",
    "\n",
    "##### Possible Response:\n",
    "\n",
    "```\n",
    "Certainly! I'd be happy to suggest a balanced meal plan for weight loss. Here's a general outline:\n",
    "\n",
    "Breakfast:\n",
    "- Whole grain toast with avocado and eggs\n",
    "- Greek yogurt with berries and nuts\n",
    "\n",
    "Lunch:\n",
    "- Grilled chicken salad with mixed greens and vinaigrette dressing\n",
    "- Quinoa bowl with vegetables and lean protein\n",
    "\n",
    "Dinner:\n",
    "- Baked fish with roasted vegetables\n",
    "- Stir-fry with tofu and brown rice\n",
    "\n",
    "Snacks:\n",
    "- Apple slices with peanut butter\n",
    "- Carrot sticks with hummus\n",
    "\n",
    "Remember to control portion sizes and stay hydrated. It's also important to consult with a nutritionist or doctor for personalized advice.\n",
    "\n",
    "Good luck with your weight loss journey!\n",
    "```\n",
    "\n",
    "The bad example lacks specificity and fails to:\n",
    "1. Ask for additional necessary information\n",
    "2. Provide specific portion sizes or calorie counts\n",
    "3. Explain the nutritional benefits of the suggestions\n",
    "4. Format the response in an easily readable manner\n",
    "5. Use consistent units of measurement\n",
    "6. Offer a comprehensive plan tailored to the user's needs\n",
    "\n",
    "#### Good Example: Nutrition Advisor Assistant\n",
    "\n",
    "##### System Instruction (Good):\n",
    "\n",
    "```python\n",
    "system_instruction = \"\"\"\n",
    "You are a nutrition advisor specialized in providing dietary recommendations. \n",
    "When responding to queries:\n",
    "1. Always ask for the user's age, weight, height, and activity level if not provided.\n",
    "2. Provide advice based on scientifically backed nutritional guidelines.\n",
    "3. Offer meal suggestions with specific portion sizes.\n",
    "4. Include a brief explanation of the nutritional benefits for each recommendation.\n",
    "5. If asked about medical conditions, remind the user to consult with a healthcare professional.\n",
    "6. Format responses in easy-to-read bullet points or numbered lists.\n",
    "7. Use metric units (kg, cm) with imperial conversions in parentheses.\n",
    "\n",
    "Do not provide advice on topics unrelated to nutrition and healthy eating habits.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "##### User Prompt:\n",
    "\n",
    "```python\n",
    "user_prompt = \"\"\"\n",
    "I'm a 30-year-old woman, 165 cm tall, weighing 70 kg. I exercise 3 times a week. \n",
    "Can you suggest a balanced meal plan for weight loss?\n",
    "\"\"\"\n",
    "\n",
    "full_prompt = f\"{system_instruction}\\n\\n{user_prompt}\"\n",
    "response = get_completion(full_prompt)\n",
    "print(response)\n",
    "```\n",
    "\n",
    "##### Possible Response:\n",
    "\n",
    "```\n",
    "Certainly! Based on the information you've provided, here's a balanced meal plan to support your weight loss goals:\n",
    "\n",
    "1. Breakfast (300-350 calories):\n",
    "   • 1 cup (90g) of oatmeal with 1 tbsp (15g) of chia seeds\n",
    "   • 1 medium apple, sliced\n",
    "   • 200ml of unsweetened almond milk\n",
    "   Benefits: High in fiber for satiety, provides slow-release energy\n",
    "\n",
    "2. Mid-morning Snack (100-150 calories):\n",
    "   • 1 small handful (30g) of unsalted mixed nuts\n",
    "   Benefits: Healthy fats and protein to curb hunger\n",
    "\n",
    "3. Lunch (400-450 calories):\n",
    "   • 120g grilled chicken breast\n",
    "   • 1 cup (150g) of mixed salad greens\n",
    "   • 1/2 cup (75g) of cherry tomatoes\n",
    "   • 1/4 avocado, sliced\n",
    "   • 1 tbsp (15ml) of olive oil and balsamic vinegar dressing\n",
    "   Benefits: Lean protein for muscle maintenance, vegetables for vitamins and fiber\n",
    "\n",
    "4. Afternoon Snack (100-150 calories):\n",
    "   • 1 medium carrot, sliced\n",
    "   • 2 tbsp (30g) of hummus\n",
    "   Benefits: Crunchy texture satisfies cravings, protein and fiber for satiety\n",
    "\n",
    "5. Dinner (400-450 calories):\n",
    "   • 150g baked salmon\n",
    "   • 1 cup (150g) of roasted Brussels sprouts\n",
    "   • 1/2 cup (75g) of quinoa\n",
    "   Benefits: Omega-3 fatty acids from salmon, complex carbs from quinoa for sustained energy\n",
    "\n",
    "6. Evening Snack (if needed, 100 calories):\n",
    "   • 1 cup (150g) of mixed berries\n",
    "   Benefits: Low in calories, high in antioxidants and fiber\n",
    "\n",
    "Remember to stay hydrated by drinking at least 8 glasses (2 liters) of water throughout the day. This meal plan provides approximately 1500-1600 calories, which should create a moderate calorie deficit for weight loss given your stats and activity level.\n",
    "\n",
    "Always listen to your body and adjust portions if needed. For personalized medical advice or if you have any health conditions, please consult with a healthcare professional or registered dietitian.\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "This comparison demonstrates how well-crafted system instructions can lead to more detailed, helpful, and tailored responses, while vague instructions may result in generic advice that doesn't fully address the user's specific situation or needs.\n",
    "\n",
    "By using system instructions, you can create AI assistants that are specialized in certain areas, adhere to specific formatting requirements, and have defined boundaries of knowledge or capabilities. This approach allows for more controlled and targeted interactions with AI models.\n",
    "\n",
    "### Practice: Creating a Specialized AI Travel Assistant with System Instructions\n",
    "\n",
    "1. Write a non-specific prompt without specifying any system instructions for a travel assistant.\n",
    "2. Rewrite the prompt to include a specific system instruction for a travel assistant. \n",
    "3. Show the class what you wrote for both prompts and explain the difference in responses from the model.\n",
    "\n",
    "Consider including instructions for (not necessarily all of these or limited to these):\n",
    "\n",
    "- Asking for specific user information (e.g., destination, dates, budget, preferences)\n",
    "-  Providing recommendations based on current travel information\n",
    "- Offering detailed itinerary suggestions with costs and time estimates\n",
    "- Including descriptions of attractions and activities\n",
    "Reminding users about official sources for visa and health information\n",
    "- Formatting responses for easy reading\n",
    "- Handling currency conversions\n",
    "- Suggesting money-saving tips\n",
    "- Providing cultural information\n",
    "- Setting boundaries on what services the assistant can and cannot provide\n",
    "\n",
    "**Note:** You will want to create your system instruction first, then redefine your get_completion function to include the system instruction as part of the prompt. See below for an example.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt,system_instruction=None, model=\"gemini-1.5-flash\", **kwargs):\n",
    "    model = genai.GenerativeModel(model)\n",
    "    \n",
    "    if system_instruction:\n",
    "        prompt = f\"{system_instruction}\\n\\n{prompt}\"\n",
    "    \n",
    "    # Create a generation_config dictionary with default values\n",
    "    generation_config = {\n",
    "        \"temperature\": 0.7,\n",
    "        \"min_length\": 20,\n",
    "        \"max_length\": 200,\n",
    "        \"max_output_tokens\": 2020,\n",
    "    }\n",
    "    \n",
    "    # Update generation_config with any provided kwargs\n",
    "    generation_config.update(kwargs)\n",
    "    \n",
    "    response = model.generate_content(prompt, generation_config=generation_config)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment and uncomment your prompts one at a time to see the difference\n",
    "# Your basic system instruction:\n",
    "system_instruction = \"\"\"\n",
    "\"\"\"\n",
    "# Your more effective and specialized system instruction:\n",
    "system_instruction = \"\"\"\n",
    "\"\"\"                         \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
